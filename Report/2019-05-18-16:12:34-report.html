<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title>Test Report</title>
    <style>body {
	font-family: Helvetica, Arial, sans-serif;
	font-size: 12px;
	min-width: 1200px;
	color: #999;
}

h1 {
	font-size: 24px;
	color: black;
}

h2 {
	font-size: 16px;
	color: black;
}

p {
    color: black;
}

a {
	color: #999;
}

table {
	border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/

#environment td {
	padding: 5px;
	border: 1px solid #E6E6E6;
}

#environment tr:nth-child(odd) {
	background-color: #f6f6f6;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed, .passed .col-result {
	color: green;
}
span.skipped, span.xfailed, span.rerun, .skipped .col-result, .xfailed .col-result, .rerun .col-result {
	color: orange;
}
span.error, span.failed, span.xpassed, .error .col-result, .failed .col-result, .xpassed .col-result  {
	color: red;
}


/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/

/*------------------
 * 1. Table Layout
 *------------------*/

#results-table {
	border: 1px solid #e6e6e6;
	color: #999;
	font-size: 12px;
	width: 100%
}

#results-table th, #results-table td {
	padding: 5px;
	border: 1px solid #E6E6E6;
	text-align: left
}
#results-table th {
	font-weight: bold
}

/*------------------
 * 2. Extra
 *------------------*/

.log:only-child {
	height: inherit
}
.log {
	background-color: #e6e6e6;
	border: 1px solid #e6e6e6;
	color: black;
	display: block;
	font-family: "Courier New", Courier, monospace;
	height: 230px;
	overflow-y: scroll;
	padding: 5px;
	white-space: pre-wrap
}
div.image {
	border: 1px solid #e6e6e6;
	float: right;
	height: 240px;
	margin-left: 5px;
	overflow: hidden;
	width: 320px
}
div.image img {
	width: 320px
}
.collapsed {
	display: none;
}
.expander::after {
	content: " (show details)";
	color: #BBB;
	font-style: italic;
	cursor: pointer;
}
.collapser::after {
	content: " (hide details)";
	color: #BBB;
	font-style: italic;
	cursor: pointer;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
	cursor: pointer;
}

.sort-icon {
	font-size: 0px;
	float: left;
	margin-right: 5px;
	margin-top: 5px;
	/*triangle*/
	width: 0;
	height: 0;
	border-left: 8px solid transparent;
	border-right: 8px solid transparent;
}

.inactive .sort-icon {
	/*finish triangle*/
	border-top: 8px solid #E6E6E6;
}

.asc.active .sort-icon {
	/*finish triangle*/
	border-bottom: 8px solid #999;
}

.desc.active .sort-icon {
	/*finish triangle*/
	border-top: 8px solid #999;
}
</style></head>
  <body onLoad="init()">
    <script>/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this file,
 * You can obtain one at http://mozilla.org/MPL/2.0/. */


function toArray(iter) {
    if (iter === null) {
        return null;
    }
    return Array.prototype.slice.call(iter);
}

function find(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return elem.querySelector(selector);
}

function find_all(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return toArray(elem.querySelectorAll(selector));
}

function sort_column(elem) {
    toggle_sort_states(elem);
    var colIndex = toArray(elem.parentNode.childNodes).indexOf(elem);
    var key;
    if (elem.classList.contains('numeric')) {
        key = key_num;
    } else if (elem.classList.contains('result')) {
        key = key_result;
    } else {
        key = key_alpha;
    }
    sort_table(elem, key(colIndex));
}

function show_all_extras() {
    find_all('.col-result').forEach(show_extras);
}

function hide_all_extras() {
    find_all('.col-result').forEach(hide_extras);
}

function show_extras(colresult_elem) {
    var extras = colresult_elem.parentNode.nextElementSibling;
    var expandcollapse = colresult_elem.firstElementChild;
    extras.classList.remove("collapsed");
    expandcollapse.classList.remove("expander");
    expandcollapse.classList.add("collapser");
}

function hide_extras(colresult_elem) {
    var extras = colresult_elem.parentNode.nextElementSibling;
    var expandcollapse = colresult_elem.firstElementChild;
    extras.classList.add("collapsed");
    expandcollapse.classList.remove("collapser");
    expandcollapse.classList.add("expander");
}

function show_filters() {
    var filter_items = document.getElementsByClassName('filter');
    for (var i = 0; i < filter_items.length; i++)
        filter_items[i].hidden = false;
}

function add_collapse() {
    // Add links for show/hide all
    var resulttable = find('table#results-table');
    var showhideall = document.createElement("p");
    showhideall.innerHTML = '<a href="javascript:show_all_extras()">Show all details</a> / ' +
                            '<a href="javascript:hide_all_extras()">Hide all details</a>';
    resulttable.parentElement.insertBefore(showhideall, resulttable);

    // Add show/hide link to each result
    find_all('.col-result').forEach(function(elem) {
        var collapsed = get_query_parameter('collapsed') || 'Passed';
        var extras = elem.parentNode.nextElementSibling;
        var expandcollapse = document.createElement("span");
        if (collapsed.includes(elem.innerHTML)) {
            extras.classList.add("collapsed");
            expandcollapse.classList.add("expander");
        } else {
            expandcollapse.classList.add("collapser");
        }
        elem.appendChild(expandcollapse);

        elem.addEventListener("click", function(event) {
            if (event.currentTarget.parentNode.nextElementSibling.classList.contains("collapsed")) {
                show_extras(event.currentTarget);
            } else {
                hide_extras(event.currentTarget);
            }
        });
    })
}

function get_query_parameter(name) {
    var match = RegExp('[?&]' + name + '=([^&]*)').exec(window.location.search);
    return match && decodeURIComponent(match[1].replace(/\+/g, ' '));
}

function init () {
    reset_sort_headers();

    add_collapse();

    show_filters();

    toggle_sort_states(find('.initial-sort'));

    find_all('.sortable').forEach(function(elem) {
        elem.addEventListener("click",
                              function(event) {
                                  sort_column(elem);
                              }, false)
    });

};

function sort_table(clicked, key_func) {
    var rows = find_all('.results-table-row');
    var reversed = !clicked.classList.contains('asc');
    var sorted_rows = sort(rows, key_func, reversed);
    /* Whole table is removed here because browsers acts much slower
     * when appending existing elements.
     */
    var thead = document.getElementById("results-table-head");
    document.getElementById('results-table').remove();
    var parent = document.createElement("table");
    parent.id = "results-table";
    parent.appendChild(thead);
    sorted_rows.forEach(function(elem) {
        parent.appendChild(elem);
    });
    document.getElementsByTagName("BODY")[0].appendChild(parent);
}

function sort(items, key_func, reversed) {
    var sort_array = items.map(function(item, i) {
        return [key_func(item), i];
    });
    var multiplier = reversed ? -1 : 1;

    sort_array.sort(function(a, b) {
        var key_a = a[0];
        var key_b = b[0];
        return multiplier * (key_a >= key_b ? 1 : -1);
    });

    return sort_array.map(function(item) {
        var index = item[1];
        return items[index];
    });
}

function key_alpha(col_index) {
    return function(elem) {
        return elem.childNodes[1].childNodes[col_index].firstChild.data.toLowerCase();
    };
}

function key_num(col_index) {
    return function(elem) {
        return parseFloat(elem.childNodes[1].childNodes[col_index].firstChild.data);
    };
}

function key_result(col_index) {
    return function(elem) {
        var strings = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed',
                       'Skipped', 'Passed'];
        return strings.indexOf(elem.childNodes[1].childNodes[col_index].firstChild.data);
    };
}

function reset_sort_headers() {
    find_all('.sort-icon').forEach(function(elem) {
        elem.parentNode.removeChild(elem);
    });
    find_all('.sortable').forEach(function(elem) {
        var icon = document.createElement("div");
        icon.className = "sort-icon";
        icon.textContent = "vvv";
        elem.insertBefore(icon, elem.firstChild);
        elem.classList.remove("desc", "active");
        elem.classList.add("asc", "inactive");
    });
}

function toggle_sort_states(elem) {
    //if active, toggle between asc and desc
    if (elem.classList.contains('active')) {
        elem.classList.toggle('asc');
        elem.classList.toggle('desc');
    }

    //if inactive, reset all other functions and add ascending active
    if (elem.classList.contains('inactive')) {
        reset_sort_headers();
        elem.classList.remove('inactive');
        elem.classList.add('active');
    }
}

function is_all_rows_hidden(value) {
  return value.hidden == false;
}

function filter_table(elem) {
    var outcome_att = "data-test-result";
    var outcome = elem.getAttribute(outcome_att);
    class_outcome = outcome + " results-table-row";
    var outcome_rows = document.getElementsByClassName(class_outcome);

    for(var i = 0; i < outcome_rows.length; i++){
        outcome_rows[i].hidden = !elem.checked;
    }

    var rows = find_all('.results-table-row').filter(is_all_rows_hidden);
    var all_rows_hidden = rows.length == 0 ? true : false;
    var not_found_message = document.getElementById("not-found-message");
    not_found_message.hidden = !all_rows_hidden;
}
</script>
    <h1>2019-05-18-16:12:34-report.html</h1>
    <p>Report generated on 18-May-2019 at 16:12:43 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a> v1.20.0</p>
    <h2>Environment</h2>
    <table id="environment">
      <tr>
        <td>Packages</td>
        <td>{&apos;pytest&apos;: &apos;4.4.1&apos;, &apos;py&apos;: &apos;1.8.0&apos;, &apos;pluggy&apos;: &apos;0.10.0&apos;}</td></tr>
      <tr>
        <td>Platform</td>
        <td>Linux-5.1.2-arch1-1-ARCH-x86_64-with-arch</td></tr>
      <tr>
        <td>Plugins</td>
        <td>{&apos;metadata&apos;: &apos;1.8.0&apos;, &apos;html&apos;: &apos;1.20.0&apos;}</td></tr>
      <tr>
        <td>Python</td>
        <td>3.7.3</td></tr></table>
    <h2>Summary</h2>
    <p>7 tests ran in 3.41 seconds. </p>
    <p class="filter" hidden="true">(Un)check the boxes to filter the results.</p><input checked="true" class="filter" data-test-result="passed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="passed">0 passed</span>, <input checked="true" class="filter" data-test-result="skipped" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="skipped">0 skipped</span>, <input checked="true" class="filter" data-test-result="failed" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="failed">7 failed</span>, <input checked="true" class="filter" data-test-result="error" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="error">0 errors</span>, <input checked="true" class="filter" data-test-result="xfailed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="xfailed">0 expected failures</span>, <input checked="true" class="filter" data-test-result="xpassed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="xpassed">0 unexpected passes</span>
    <h2>Results</h2>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th>No.</th>
          <th class="sortable result initial-sort" col="result">Result</th>
          <th class="sortable" col="name">Test</th>
          <th>Description</th>
          <th class="sortable numeric" col="duration">Duration</th>
          <th>Params</th></tr>
        <tr hidden="true" id="not-found-message">
          <th colspan="6">No results found. Try to check the filters</th></tr></thead>
      <tbody class="failed results-table-row">
        <tr>
          <td>1.0</td>
          <td class="col-result">Failed</td>
          <td class="col-name">添加人物信息 -- POST -- super_table/add/</td>
          <td>姓名参数为空</td>
          <td class="col-duration">0.01</td>
          <td>{&quot;name&quot;: &quot;&quot;, &quot;tel&quot;: &quot;1234567&quot;, &quot;address&quot;: &quot;漫威宇宙&quot;}</td></tr>
        <tr>
          <td class="extra" colspan="6">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:160: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:80: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:70: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95d05080&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;<br/>body = &#x27;data=9Uc7G6A-xj7qT9KtEbkFjAraFJfbWp_NC4UbK3uDWt-fq67bPRXtcGmXmKbbKIkQn15c48l3mRsJmX_2J5IXNzHCyenOBopS4zUNQrJea40%3D&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;115&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95d05128&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95d05668&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95d05080&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95d05668&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: &#x27;data=9Uc7G6A-xj7qT9KtEbkFjAraFJfbWp_NC4UbK3uDWt-fq67bPRXtcGmXmKbbKIkQn15c48l3mRsJmX_2J5IXNzHCyenOBopS4zUNQrJ...ept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;115&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a965d46d8&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>        Perform a request on a given urllib connection object taken from our<br/>        pool.<br/>    <br/>        :param conn:<br/>            a connection from one of our connection pools<br/>    <br/>        :param timeout:<br/>            Socket timeout in seconds for the request. This can be a<br/>            float or integer, which will set the same timeout value for<br/>            the socket connect and the socket read, or an instance of<br/>            :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>            control over your timeouts.<br/>        &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:355: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;<br/>body = &#x27;data=9Uc7G6A-xj7qT9KtEbkFjAraFJfbWp_NC4UbK3uDWt-fq67bPRXtcGmXmKbbKIkQn15c48l3mRsJmX_2J5IXNzHCyenOBopS4zUNQrJea40%3D&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;115&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1229: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;<br/>body = b&#x27;data=9Uc7G6A-xj7qT9KtEbkFjAraFJfbWp_NC4UbK3uDWt-fq67bPRXtcGmXmKbbKIkQn15c48l3mRsJmX_2J5IXNzHCyenOBopS4zUNQrJea40%3D&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;115&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1275: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;<br/>message_body = b&#x27;data=9Uc7G6A-xj7qT9KtEbkFjAraFJfbWp_NC4UbK3uDWt-fq67bPRXtcGmXmKbbKIkQn15c48l3mRsJmX_2J5IXNzHCyenOBopS4zUNQrJea40%3D&#x27;<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>        This method sends the request to the server.  The optional message_body<br/>        argument can be used to pass a message body associated with the<br/>        request.<br/>        &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1224: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;<br/>message_body = b&#x27;data=9Uc7G6A-xj7qT9KtEbkFjAraFJfbWp_NC4UbK3uDWt-fq67bPRXtcGmXmKbbKIkQn15c48l3mRsJmX_2J5IXNzHCyenOBopS4zUNQrJea40%3D&#x27;<br/>encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>        Appends an extra \\r\\n to the buffer.<br/>        A message_body may be specified, to be appended to the request.<br/>        &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/lib/python3.7/http/client.py:1016: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;<br/>data = b&#x27;POST /super_table/add/ HTTP/1.1\r\nHost: 127.0.0.1:8000\r\nUser-Agent: python-requests/2.22.0\r\nAccept-Encoding: gz...ccept: */*\r\nConnection: keep-alive\r\nContent-Length: 115\r\nContent-Type: application/x-www-form-urlencoded\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>        ``data`` can be a string object, a bytes object, an array object, a<br/>        file-like object that supports a .read() method, or an iterable object.<br/>        &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/lib/python3.7/http/client.py:956: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:183: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:169: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a95cff9b0&gt;<br/>request = &lt;PreparedRequest [POST]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95d05128&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:449: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95d05080&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;<br/>body = &#x27;data=9Uc7G6A-xj7qT9KtEbkFjAraFJfbWp_NC4UbK3uDWt-fq67bPRXtcGmXmKbbKIkQn15c48l3mRsJmX_2J5IXNzHCyenOBopS4zUNQrJea40%3D&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;115&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95d05128&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95d05668&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:641: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95d05080&gt;<br/>_stacktrace = &lt;traceback object at 0x7f7a95c9ccc8&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>        :param response: A response object, or None, if the server did not<br/>            return a response.<br/>        :type response: :class:`~urllib3.response.HTTPResponse`<br/>        :param Exception error: An error encountered during the request, or<br/>            None if the response was received successfully.<br/>    <br/>        :return: A new ``Retry`` object.<br/>        &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/add/ (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/retry.py:399: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;test_main.TestApi object at 0x7f7a961beeb8&gt;, num = 1.0<br/>api_name = &#x27;添加人物信息&#x27;, description = &#x27;姓名参数为空&#x27;<br/>api_host = &#x27;http://127.0.0.1:8000/\n&#x27;, request_url = &#x27;super_table/add/&#x27;<br/>request_method = &#x27;POST&#x27;<br/>request_data = &#x27;{&quot;name&quot;: &quot;&quot;, &quot;tel&quot;: &quot;1234567&quot;, &quot;address&quot;: &quot;漫威宇宙&quot;}&#x27;<br/>encryption_method = &#x27;AES&#x27;, check_point = &#x27;400:parameter error&#x27;<br/>active = &#x27;yes&#x27;<br/><br/>    @pytest.mark.parametrize(&#x27;num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active&#x27;, excel)<br/>    # 测试用例<br/>    def test_api(self, num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active):<br/>        # 拼接出完整请求地址<br/>        url = api_host.replace(&#x27;\n&#x27;, &#x27;&#x27;).replace(&#x27;\r&#x27;, &#x27;&#x27;) + request_url<br/>        # 以防万一，如果用例未激活则跳过<br/>        if active == &quot;no&quot;:<br/>            pytest.skip(&quot;active为no，跳过该测试用例&quot;)<br/>        elif active == &quot;yes&quot;:<br/>            # 处理GET请求<br/>            if  request_method == &quot;GET&quot;:<br/>                # 如果请求需要MD5签名<br/>                if encryption_method == &#x27;MD5&#x27;:<br/>                    data = json.loads(request_data)<br/>                    sign = encryption.MD5_sign()<br/>                    data.update(md5_sign=sign)<br/>                    session = requests.Session()<br/>                    # 禁止代理服务<br/>                    session.trust_env = False<br/>                    r = session.get(url, params=data)<br/>                else:<br/>                    session = requests.Session()<br/>                    session.trust_env = False<br/>                    r = session.get(url, params=request_data)<br/>    <br/>            # 处理POST请求<br/>            elif request_method  == &quot;POST&quot;:<br/>                data = json.loads(request_data)<br/>                session = requests.Session()<br/>                session.trust_env = False<br/>                # AES加密处理<br/>                if encryption_method == &#x27;AES&#x27;:<br/>                    encoded = encryption.encryptAES(json.dumps(data)).decode()<br/>&gt;                   r = session.post(url, data={&#x27;data&#x27;: encoded})<br/><br/>test_main.py:49: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:581: in post<br/>    return self.request(&#x27;POST&#x27;, url, data=data, json=json, **kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:533: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:646: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a95cff9b0&gt;<br/>request = &lt;PreparedRequest [POST]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95d05128&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7, use buffering of HTTP responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 3.3+<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/add/ (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95d056a0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:516: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td>2.0</td>
          <td class="col-result">Failed</td>
          <td class="col-name">添加人物信息 -- POST -- super_table/add/</td>
          <td>姓名参数重复</td>
          <td class="col-duration">0.00</td>
          <td>{&quot;name&quot;: &quot;天启&quot;, &quot;tel&quot;: &quot;1234567&quot;, &quot;address&quot;: &quot;漫威宇宙&quot;}</td></tr>
        <tr>
          <td class="extra" colspan="6">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:160: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:80: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:70: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95b2bac8&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;<br/>body = &#x27;data=0DiIKgkyfxevXYJH8WLIhR_DSBHJKLdhGaumAipRjRPZI-fO6iYim4jRBB6tGwmp6P6pFvVkc8kkt1PuJYR8zHcclHx4-JpNl68kX3S8UOYmpE8MBaH1hy1f1qhzkYdp&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;133&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95b2bd68&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95b2bf28&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95b2bac8&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95b2bf28&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: &#x27;data=0DiIKgkyfxevXYJH8WLIhR_DSBHJKLdhGaumAipRjRPZI-fO6iYim4jRBB6tGwmp6P6pFvVkc8kkt1PuJYR8zHcclHx4-JpNl68kX3S...ept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;133&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95b2bef0&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>        Perform a request on a given urllib connection object taken from our<br/>        pool.<br/>    <br/>        :param conn:<br/>            a connection from one of our connection pools<br/>    <br/>        :param timeout:<br/>            Socket timeout in seconds for the request. This can be a<br/>            float or integer, which will set the same timeout value for<br/>            the socket connect and the socket read, or an instance of<br/>            :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>            control over your timeouts.<br/>        &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:355: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;<br/>body = &#x27;data=0DiIKgkyfxevXYJH8WLIhR_DSBHJKLdhGaumAipRjRPZI-fO6iYim4jRBB6tGwmp6P6pFvVkc8kkt1PuJYR8zHcclHx4-JpNl68kX3S8UOYmpE8MBaH1hy1f1qhzkYdp&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;133&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1229: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;<br/>body = b&#x27;data=0DiIKgkyfxevXYJH8WLIhR_DSBHJKLdhGaumAipRjRPZI-fO6iYim4jRBB6tGwmp6P6pFvVkc8kkt1PuJYR8zHcclHx4-JpNl68kX3S8UOYmpE8MBaH1hy1f1qhzkYdp&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;133&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1275: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;<br/>message_body = b&#x27;data=0DiIKgkyfxevXYJH8WLIhR_DSBHJKLdhGaumAipRjRPZI-fO6iYim4jRBB6tGwmp6P6pFvVkc8kkt1PuJYR8zHcclHx4-JpNl68kX3S8UOYmpE8MBaH1hy1f1qhzkYdp&#x27;<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>        This method sends the request to the server.  The optional message_body<br/>        argument can be used to pass a message body associated with the<br/>        request.<br/>        &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1224: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;<br/>message_body = b&#x27;data=0DiIKgkyfxevXYJH8WLIhR_DSBHJKLdhGaumAipRjRPZI-fO6iYim4jRBB6tGwmp6P6pFvVkc8kkt1PuJYR8zHcclHx4-JpNl68kX3S8UOYmpE8MBaH1hy1f1qhzkYdp&#x27;<br/>encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>        Appends an extra \\r\\n to the buffer.<br/>        A message_body may be specified, to be appended to the request.<br/>        &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/lib/python3.7/http/client.py:1016: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;<br/>data = b&#x27;POST /super_table/add/ HTTP/1.1\r\nHost: 127.0.0.1:8000\r\nUser-Agent: python-requests/2.22.0\r\nAccept-Encoding: gz...ccept: */*\r\nConnection: keep-alive\r\nContent-Length: 133\r\nContent-Type: application/x-www-form-urlencoded\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>        ``data`` can be a string object, a bytes object, an array object, a<br/>        file-like object that supports a .read() method, or an iterable object.<br/>        &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/lib/python3.7/http/client.py:956: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:183: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:169: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a95b43cc0&gt;<br/>request = &lt;PreparedRequest [POST]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95b2bd68&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:449: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95b2bac8&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;<br/>body = &#x27;data=0DiIKgkyfxevXYJH8WLIhR_DSBHJKLdhGaumAipRjRPZI-fO6iYim4jRBB6tGwmp6P6pFvVkc8kkt1PuJYR8zHcclHx4-JpNl68kX3S8UOYmpE8MBaH1hy1f1qhzkYdp&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;133&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95b2bd68&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95b2bf28&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:641: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;POST&#x27;, url = &#x27;/super_table/add/&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95b2bac8&gt;<br/>_stacktrace = &lt;traceback object at 0x7f7a95ad9ac8&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>        :param response: A response object, or None, if the server did not<br/>            return a response.<br/>        :type response: :class:`~urllib3.response.HTTPResponse`<br/>        :param Exception error: An error encountered during the request, or<br/>            None if the response was received successfully.<br/>    <br/>        :return: A new ``Retry`` object.<br/>        &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/add/ (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/retry.py:399: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;test_main.TestApi object at 0x7f7a95cff080&gt;, num = 2.0<br/>api_name = &#x27;添加人物信息&#x27;, description = &#x27;姓名参数重复&#x27;<br/>api_host = &#x27;http://127.0.0.1:8000/\n&#x27;, request_url = &#x27;super_table/add/&#x27;<br/>request_method = &#x27;POST&#x27;<br/>request_data = &#x27;{&quot;name&quot;: &quot;天启&quot;, &quot;tel&quot;: &quot;1234567&quot;, &quot;address&quot;: &quot;漫威宇宙&quot;}&#x27;<br/>encryption_method = &#x27;AES&#x27;, check_point = &#x27;410:name already exists&#x27;<br/>active = &#x27;yes&#x27;<br/><br/>    @pytest.mark.parametrize(&#x27;num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active&#x27;, excel)<br/>    # 测试用例<br/>    def test_api(self, num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active):<br/>        # 拼接出完整请求地址<br/>        url = api_host.replace(&#x27;\n&#x27;, &#x27;&#x27;).replace(&#x27;\r&#x27;, &#x27;&#x27;) + request_url<br/>        # 以防万一，如果用例未激活则跳过<br/>        if active == &quot;no&quot;:<br/>            pytest.skip(&quot;active为no，跳过该测试用例&quot;)<br/>        elif active == &quot;yes&quot;:<br/>            # 处理GET请求<br/>            if  request_method == &quot;GET&quot;:<br/>                # 如果请求需要MD5签名<br/>                if encryption_method == &#x27;MD5&#x27;:<br/>                    data = json.loads(request_data)<br/>                    sign = encryption.MD5_sign()<br/>                    data.update(md5_sign=sign)<br/>                    session = requests.Session()<br/>                    # 禁止代理服务<br/>                    session.trust_env = False<br/>                    r = session.get(url, params=data)<br/>                else:<br/>                    session = requests.Session()<br/>                    session.trust_env = False<br/>                    r = session.get(url, params=request_data)<br/>    <br/>            # 处理POST请求<br/>            elif request_method  == &quot;POST&quot;:<br/>                data = json.loads(request_data)<br/>                session = requests.Session()<br/>                session.trust_env = False<br/>                # AES加密处理<br/>                if encryption_method == &#x27;AES&#x27;:<br/>                    encoded = encryption.encryptAES(json.dumps(data)).decode()<br/>&gt;                   r = session.post(url, data={&#x27;data&#x27;: encoded})<br/><br/>test_main.py:49: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:581: in post<br/>    return self.request(&#x27;POST&#x27;, url, data=data, json=json, **kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:533: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:646: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a95b43cc0&gt;<br/>request = &lt;PreparedRequest [POST]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95b2bd68&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7, use buffering of HTTP responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 3.3+<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/add/ (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95b2be80&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:516: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td>3.0</td>
          <td class="col-result">Failed</td>
          <td class="col-name">添加人物信息 -- GET -- super_table/add/</td>
          <td>使用GET请求</td>
          <td class="col-duration">0.00</td>
          <td>{&quot;name&quot;: &quot;天启&quot;, &quot;tel&quot;: &quot;1234567&quot;, &quot;address&quot;: &quot;漫威宇宙&quot;}</td></tr>
        <tr>
          <td class="extra" colspan="6">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:160: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:80: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:70: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95abc208&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/add/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22,%20%22tel%22:%20%221234567%22,%20%22address%22:%20%22%E6%BC%AB%E5%A8%81%E5%AE%87%E5%AE%99%22%7D&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95abcda0&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95aaa9b0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95abc208&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/add/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22,%20%22tel%22:%20%221234567%22,%20%22address%22:%20%22%E6%BC%AB%E5%A8%81%E5%AE%87%E5%AE%99%22%7D&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95aaa9b0&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95aaa940&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>        Perform a request on a given urllib connection object taken from our<br/>        pool.<br/>    <br/>        :param conn:<br/>            a connection from one of our connection pools<br/>    <br/>        :param timeout:<br/>            Socket timeout in seconds for the request. This can be a<br/>            float or integer, which will set the same timeout value for<br/>            the socket connect and the socket read, or an instance of<br/>            :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>            control over your timeouts.<br/>        &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:355: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/add/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22,%20%22tel%22:%20%221234567%22,%20%22address%22:%20%22%E6%BC%AB%E5%A8%81%E5%AE%87%E5%AE%99%22%7D&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1229: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/add/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22,%20%22tel%22:%20%221234567%22,%20%22address%22:%20%22%E6%BC%AB%E5%A8%81%E5%AE%87%E5%AE%99%22%7D&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1275: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>        This method sends the request to the server.  The optional message_body<br/>        argument can be used to pass a message body associated with the<br/>        request.<br/>        &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1224: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>        Appends an extra \\r\\n to the buffer.<br/>        A message_body may be specified, to be appended to the request.<br/>        &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/lib/python3.7/http/client.py:1016: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;<br/>data = b&#x27;GET /super_table/add/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22,%20%22tel%22:%20%221234567%22,%20%22address%22:%20%2...nUser-Agent: python-requests/2.22.0\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>        ``data`` can be a string object, a bytes object, an array object, a<br/>        file-like object that supports a .read() method, or an iterable object.<br/>        &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/lib/python3.7/http/client.py:956: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:183: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:169: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a95a93048&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95abcda0&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:449: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95abc208&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/add/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22,%20%22tel%22:%20%221234567%22,%20%22address%22:%20%22%E6%BC%AB%E5%A8%81%E5%AE%87%E5%AE%99%22%7D&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95abcda0&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95aaa9b0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:641: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/add/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22,%20%22tel%22:%20%221234567%22,%20%22address%22:%20%22%E6%BC%AB%E5%A8%81%E5%AE%87%E5%AE%99%22%7D&#x27;<br/>response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95abc208&gt;<br/>_stacktrace = &lt;traceback object at 0x7f7a95aa8148&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>        :param response: A response object, or None, if the server did not<br/>            return a response.<br/>        :type response: :class:`~urllib3.response.HTTPResponse`<br/>        :param Exception error: An error encountered during the request, or<br/>            None if the response was received successfully.<br/>    <br/>        :return: A new ``Retry`` object.<br/>        &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/add/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22,%20%22tel%22:%20%221234567%22,%20%22address%22:%20%22%E6%BC%AB%E5%A8%81%E5%AE%87%E5%AE%99%22%7D (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/retry.py:399: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;test_main.TestApi object at 0x7f7a95cffac8&gt;, num = 3.0<br/>api_name = &#x27;添加人物信息&#x27;, description = &#x27;使用GET请求&#x27;<br/>api_host = &#x27;http://127.0.0.1:8000/\n&#x27;, request_url = &#x27;super_table/add/&#x27;<br/>request_method = &#x27;GET&#x27;<br/>request_data = &#x27;{&quot;name&quot;: &quot;天启&quot;, &quot;tel&quot;: &quot;1234567&quot;, &quot;address&quot;: &quot;漫威宇宙&quot;}&#x27;<br/>encryption_method = &#x27;AES&#x27;, check_point = &#x27;405:method not allowed&#x27;<br/>active = &#x27;yes&#x27;<br/><br/>    @pytest.mark.parametrize(&#x27;num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active&#x27;, excel)<br/>    # 测试用例<br/>    def test_api(self, num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active):<br/>        # 拼接出完整请求地址<br/>        url = api_host.replace(&#x27;\n&#x27;, &#x27;&#x27;).replace(&#x27;\r&#x27;, &#x27;&#x27;) + request_url<br/>        # 以防万一，如果用例未激活则跳过<br/>        if active == &quot;no&quot;:<br/>            pytest.skip(&quot;active为no，跳过该测试用例&quot;)<br/>        elif active == &quot;yes&quot;:<br/>            # 处理GET请求<br/>            if  request_method == &quot;GET&quot;:<br/>                # 如果请求需要MD5签名<br/>                if encryption_method == &#x27;MD5&#x27;:<br/>                    data = json.loads(request_data)<br/>                    sign = encryption.MD5_sign()<br/>                    data.update(md5_sign=sign)<br/>                    session = requests.Session()<br/>                    # 禁止代理服务<br/>                    session.trust_env = False<br/>                    r = session.get(url, params=data)<br/>                else:<br/>                    session = requests.Session()<br/>                    session.trust_env = False<br/>&gt;                   r = session.get(url, params=request_data)<br/><br/>test_main.py:39: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:546: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:533: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:646: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a95a93048&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95abcda0&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7, use buffering of HTTP responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 3.3+<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/add/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22,%20%22tel%22:%20%221234567%22,%20%22address%22:%20%22%E6%BC%AB%E5%A8%81%E5%AE%87%E5%AE%99%22%7D (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95aaa518&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:516: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td>1.0</td>
          <td class="col-result">Failed</td>
          <td class="col-name">查询人物信息 -- GET -- super_table/search_by_name/</td>
          <td>姓名为空</td>
          <td class="col-duration">0.00</td>
          <td>{&quot;name&quot;: &quot;&quot;}</td></tr>
        <tr>
          <td class="extra" colspan="6">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:160: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:80: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:70: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95796b38&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95796dd8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95796f28&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95796b38&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95796f28&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95796f98&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>        Perform a request on a given urllib connection object taken from our<br/>        pool.<br/>    <br/>        :param conn:<br/>            a connection from one of our connection pools<br/>    <br/>        :param timeout:<br/>            Socket timeout in seconds for the request. This can be a<br/>            float or integer, which will set the same timeout value for<br/>            the socket connect and the socket read, or an instance of<br/>            :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>            control over your timeouts.<br/>        &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:355: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1229: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1275: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>        This method sends the request to the server.  The optional message_body<br/>        argument can be used to pass a message body associated with the<br/>        request.<br/>        &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1224: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>        Appends an extra \\r\\n to the buffer.<br/>        A message_body may be specified, to be appended to the request.<br/>        &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/lib/python3.7/http/client.py:1016: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;<br/>data = b&#x27;GET /super_table/search_by_name/?name=&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162 HTTP/1.1\r\nHost: 127....nUser-Agent: python-requests/2.22.0\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>        ``data`` can be a string object, a bytes object, an array object, a<br/>        file-like object that supports a .read() method, or an iterable object.<br/>        &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/lib/python3.7/http/client.py:956: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:183: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:169: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a95921ba8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95796dd8&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:449: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95796b38&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95796dd8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95796f28&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:641: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95796b38&gt;<br/>_stacktrace = &lt;traceback object at 0x7f7a957c2c48&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>        :param response: A response object, or None, if the server did not<br/>            return a response.<br/>        :type response: :class:`~urllib3.response.HTTPResponse`<br/>        :param Exception error: An error encountered during the request, or<br/>            None if the response was received successfully.<br/>    <br/>        :return: A new ``Retry`` object.<br/>        &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/search_by_name/?name=&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162 (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/retry.py:399: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;test_main.TestApi object at 0x7f7a95b2b6d8&gt;, num = 1.0<br/>api_name = &#x27;查询人物信息&#x27;, description = &#x27;姓名为空&#x27;<br/>api_host = &#x27;http://127.0.0.1:8000/\n&#x27;<br/>request_url = &#x27;super_table/search_by_name/&#x27;, request_method = &#x27;GET&#x27;<br/>request_data = &#x27;{&quot;name&quot;: &quot;&quot;}&#x27;, encryption_method = &#x27;MD5&#x27;<br/>check_point = &#x27;400:please input a name&#x27;, active = &#x27;yes&#x27;<br/><br/>    @pytest.mark.parametrize(&#x27;num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active&#x27;, excel)<br/>    # 测试用例<br/>    def test_api(self, num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active):<br/>        # 拼接出完整请求地址<br/>        url = api_host.replace(&#x27;\n&#x27;, &#x27;&#x27;).replace(&#x27;\r&#x27;, &#x27;&#x27;) + request_url<br/>        # 以防万一，如果用例未激活则跳过<br/>        if active == &quot;no&quot;:<br/>            pytest.skip(&quot;active为no，跳过该测试用例&quot;)<br/>        elif active == &quot;yes&quot;:<br/>            # 处理GET请求<br/>            if  request_method == &quot;GET&quot;:<br/>                # 如果请求需要MD5签名<br/>                if encryption_method == &#x27;MD5&#x27;:<br/>                    data = json.loads(request_data)<br/>                    sign = encryption.MD5_sign()<br/>                    data.update(md5_sign=sign)<br/>                    session = requests.Session()<br/>                    # 禁止代理服务<br/>                    session.trust_env = False<br/>&gt;                   r = session.get(url, params=data)<br/><br/>test_main.py:35: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:546: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:533: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:646: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a95921ba8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95796dd8&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7, use buffering of HTTP responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 3.3+<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/search_by_name/?name=&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162 (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a95796f60&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:516: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td>2.0</td>
          <td class="col-result">Failed</td>
          <td class="col-name">查询人物信息 -- GET -- super_table/search_by_name/</td>
          <td>无数字签名</td>
          <td class="col-duration">0.00</td>
          <td>{&quot;name&quot;: &quot;天启&quot;}</td></tr>
        <tr>
          <td class="extra" colspan="6">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:160: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:80: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:70: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a9575ebe0&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22%7D&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9575ee48&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9575ecc0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a9575ebe0&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22%7D&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9575ecc0&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9575ed68&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>        Perform a request on a given urllib connection object taken from our<br/>        pool.<br/>    <br/>        :param conn:<br/>            a connection from one of our connection pools<br/>    <br/>        :param timeout:<br/>            Socket timeout in seconds for the request. This can be a<br/>            float or integer, which will set the same timeout value for<br/>            the socket connect and the socket read, or an instance of<br/>            :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>            control over your timeouts.<br/>        &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:355: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22%7D&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1229: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22%7D&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1275: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>        This method sends the request to the server.  The optional message_body<br/>        argument can be used to pass a message body associated with the<br/>        request.<br/>        &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1224: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>        Appends an extra \\r\\n to the buffer.<br/>        A message_body may be specified, to be appended to the request.<br/>        &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/lib/python3.7/http/client.py:1016: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;<br/>data = b&#x27;GET /super_table/search_by_name/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22%7D HTTP/1.1\r\nHost: 127.0.0.1:8000\r\nUser-Agent: python-requests/2.22.0\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>        ``data`` can be a string object, a bytes object, an array object, a<br/>        file-like object that supports a .read() method, or an iterable object.<br/>        &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/lib/python3.7/http/client.py:956: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:183: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:169: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a95759080&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9575ee48&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:449: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a9575ebe0&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22%7D&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9575ee48&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9575ecc0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:641: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22%7D&#x27;<br/>response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a9575ebe0&gt;<br/>_stacktrace = &lt;traceback object at 0x7f7a956a6908&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>        :param response: A response object, or None, if the server did not<br/>            return a response.<br/>        :type response: :class:`~urllib3.response.HTTPResponse`<br/>        :param Exception error: An error encountered during the request, or<br/>            None if the response was received successfully.<br/>    <br/>        :return: A new ``Retry`` object.<br/>        &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/search_by_name/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22%7D (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/retry.py:399: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;test_main.TestApi object at 0x7f7a95abcc18&gt;, num = 2.0<br/>api_name = &#x27;查询人物信息&#x27;, description = &#x27;无数字签名&#x27;<br/>api_host = &#x27;http://127.0.0.1:8000/\n&#x27;<br/>request_url = &#x27;super_table/search_by_name/&#x27;, request_method = &#x27;GET&#x27;<br/>request_data = &#x27;{&quot;name&quot;: &quot;天启&quot;}&#x27;, encryption_method = &#x27;no&#x27;<br/>check_point = &#x27;401:sign is empty&#x27;, active = &#x27;yes&#x27;<br/><br/>    @pytest.mark.parametrize(&#x27;num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active&#x27;, excel)<br/>    # 测试用例<br/>    def test_api(self, num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active):<br/>        # 拼接出完整请求地址<br/>        url = api_host.replace(&#x27;\n&#x27;, &#x27;&#x27;).replace(&#x27;\r&#x27;, &#x27;&#x27;) + request_url<br/>        # 以防万一，如果用例未激活则跳过<br/>        if active == &quot;no&quot;:<br/>            pytest.skip(&quot;active为no，跳过该测试用例&quot;)<br/>        elif active == &quot;yes&quot;:<br/>            # 处理GET请求<br/>            if  request_method == &quot;GET&quot;:<br/>                # 如果请求需要MD5签名<br/>                if encryption_method == &#x27;MD5&#x27;:<br/>                    data = json.loads(request_data)<br/>                    sign = encryption.MD5_sign()<br/>                    data.update(md5_sign=sign)<br/>                    session = requests.Session()<br/>                    # 禁止代理服务<br/>                    session.trust_env = False<br/>                    r = session.get(url, params=data)<br/>                else:<br/>                    session = requests.Session()<br/>                    session.trust_env = False<br/>&gt;                   r = session.get(url, params=request_data)<br/><br/>test_main.py:39: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:546: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:533: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:646: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a95759080&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9575ee48&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7, use buffering of HTTP responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 3.3+<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/search_by_name/?%7B%22name%22:%20%22%E5%A4%A9%E5%90%AF%22%7D (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a9575ecf8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:516: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td>3.0</td>
          <td class="col-result">Failed</td>
          <td class="col-name">查询人物信息 -- GET -- super_table/search_by_name/</td>
          <td>查询结果为空</td>
          <td class="col-duration">0.00</td>
          <td>{&quot;name&quot;: &quot;咔咔咔&quot;}</td></tr>
        <tr>
          <td class="extra" colspan="6">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:160: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:80: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:70: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95657da0&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E5%92%94%E5%92%94%E5%92%94&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95657f60&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9565d2b0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95657da0&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E5%92%94%E5%92%94%E5%92%94&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9565d2b0&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9565d208&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>        Perform a request on a given urllib connection object taken from our<br/>        pool.<br/>    <br/>        :param conn:<br/>            a connection from one of our connection pools<br/>    <br/>        :param timeout:<br/>            Socket timeout in seconds for the request. This can be a<br/>            float or integer, which will set the same timeout value for<br/>            the socket connect and the socket read, or an instance of<br/>            :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>            control over your timeouts.<br/>        &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:355: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E5%92%94%E5%92%94%E5%92%94&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1229: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E5%92%94%E5%92%94%E5%92%94&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1275: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>        This method sends the request to the server.  The optional message_body<br/>        argument can be used to pass a message body associated with the<br/>        request.<br/>        &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1224: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>        Appends an extra \\r\\n to the buffer.<br/>        A message_body may be specified, to be appended to the request.<br/>        &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/lib/python3.7/http/client.py:1016: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;<br/>data = b&#x27;GET /super_table/search_by_name/?name=%E5%92%94%E5%92%94%E5%92%94&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C155816...nUser-Agent: python-requests/2.22.0\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>        ``data`` can be a string object, a bytes object, an array object, a<br/>        file-like object that supports a .read() method, or an iterable object.<br/>        &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/lib/python3.7/http/client.py:956: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:183: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:169: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a956e2208&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95657f60&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:449: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95657da0&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E5%92%94%E5%92%94%E5%92%94&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95657f60&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a9565d2b0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:641: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E5%92%94%E5%92%94%E5%92%94&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162&#x27;<br/>response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a95657da0&gt;<br/>_stacktrace = &lt;traceback object at 0x7f7a9598f7c8&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>        :param response: A response object, or None, if the server did not<br/>            return a response.<br/>        :type response: :class:`~urllib3.response.HTTPResponse`<br/>        :param Exception error: An error encountered during the request, or<br/>            None if the response was received successfully.<br/>    <br/>        :return: A new ``Retry`` object.<br/>        &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/search_by_name/?name=%E5%92%94%E5%92%94%E5%92%94&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162 (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/retry.py:399: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;test_main.TestApi object at 0x7f7a95796780&gt;, num = 3.0<br/>api_name = &#x27;查询人物信息&#x27;, description = &#x27;查询结果为空&#x27;<br/>api_host = &#x27;http://127.0.0.1:8000/\n&#x27;<br/>request_url = &#x27;super_table/search_by_name/&#x27;, request_method = &#x27;GET&#x27;<br/>request_data = &#x27;{&quot;name&quot;: &quot;咔咔咔&quot;}&#x27;, encryption_method = &#x27;MD5&#x27;<br/>check_point = &#x27;204:result is empty&#x27;, active = &#x27;yes&#x27;<br/><br/>    @pytest.mark.parametrize(&#x27;num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active&#x27;, excel)<br/>    # 测试用例<br/>    def test_api(self, num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active):<br/>        # 拼接出完整请求地址<br/>        url = api_host.replace(&#x27;\n&#x27;, &#x27;&#x27;).replace(&#x27;\r&#x27;, &#x27;&#x27;) + request_url<br/>        # 以防万一，如果用例未激活则跳过<br/>        if active == &quot;no&quot;:<br/>            pytest.skip(&quot;active为no，跳过该测试用例&quot;)<br/>        elif active == &quot;yes&quot;:<br/>            # 处理GET请求<br/>            if  request_method == &quot;GET&quot;:<br/>                # 如果请求需要MD5签名<br/>                if encryption_method == &#x27;MD5&#x27;:<br/>                    data = json.loads(request_data)<br/>                    sign = encryption.MD5_sign()<br/>                    data.update(md5_sign=sign)<br/>                    session = requests.Session()<br/>                    # 禁止代理服务<br/>                    session.trust_env = False<br/>&gt;                   r = session.get(url, params=data)<br/><br/>test_main.py:35: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:546: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:533: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:646: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a956e2208&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a95657f60&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7, use buffering of HTTP responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 3.3+<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/search_by_name/?name=%E5%92%94%E5%92%94%E5%92%94&amp;md5_sign=8097513cf19d4635a65002a93a5475ae%7C1558167162 (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a9565d320&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:516: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td>4.0</td>
          <td class="col-result">Failed</td>
          <td class="col-name">查询人物信息 -- GET -- super_table/search_by_name/</td>
          <td>查询成功</td>
          <td class="col-duration">0.00</td>
          <td>{&quot;name&quot;: &quot;灭霸&quot;}</td></tr>
        <tr>
          <td class="extra" colspan="6">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:160: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:80: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>address = (&#x27;127.0.0.1&#x27;, 8000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/connection.py:70: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a956e8cc0&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E7%81%AD%E9%9C%B8&amp;md5_sign=327fbe6a4c7a11276180db4f75f1f8ed%7C1558167163&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a956e8e48&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a956ff208&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:603: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a956e8cc0&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E7%81%AD%E9%9C%B8&amp;md5_sign=327fbe6a4c7a11276180db4f75f1f8ed%7C1558167163&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a956ff208&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a956ff278&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>        Perform a request on a given urllib connection object taken from our<br/>        pool.<br/>    <br/>        :param conn:<br/>            a connection from one of our connection pools<br/>    <br/>        :param timeout:<br/>            Socket timeout in seconds for the request. This can be a<br/>            float or integer, which will set the same timeout value for<br/>            the socket connect and the socket read, or an instance of<br/>            :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>            control over your timeouts.<br/>        &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:355: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E7%81%AD%E9%9C%B8&amp;md5_sign=327fbe6a4c7a11276180db4f75f1f8ed%7C1558167163&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1229: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E7%81%AD%E9%9C%B8&amp;md5_sign=327fbe6a4c7a11276180db4f75f1f8ed%7C1558167163&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1275: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>        This method sends the request to the server.  The optional message_body<br/>        argument can be used to pass a message body associated with the<br/>        request.<br/>        &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/lib/python3.7/http/client.py:1224: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>        Appends an extra \\r\\n to the buffer.<br/>        A message_body may be specified, to be appended to the request.<br/>        &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/lib/python3.7/http/client.py:1016: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;<br/>data = b&#x27;GET /super_table/search_by_name/?name=%E7%81%AD%E9%9C%B8&amp;md5_sign=327fbe6a4c7a11276180db4f75f1f8ed%7C1558167163 HTTP...nUser-Agent: python-requests/2.22.0\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>        ``data`` can be a string object, a bytes object, an array object, a<br/>        file-like object that supports a .read() method, or an iterable object.<br/>        &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/lib/python3.7/http/client.py:956: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:183: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>        :return: New socket connection.<br/>        &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/connection.py:169: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a955e8898&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a956e8e48&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:449: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a956e8cc0&gt;<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E7%81%AD%E9%9C%B8&amp;md5_sign=327fbe6a4c7a11276180db4f75f1f8ed%7C1558167163&#x27;<br/>body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.22.0&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a956e8e48&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}<br/>conn = None, release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f7a956ff208&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>        Get a connection from the pool and perform an HTTP request. This is the<br/>        lowest level call for making a request, so you&#x27;ll need to specify all<br/>        the raw details.<br/>    <br/>        .. note::<br/>    <br/>           More commonly, it&#x27;s appropriate to use a convenience method provided<br/>           by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>        .. note::<br/>    <br/>           `release_conn` will only behave as expected if<br/>           `preload_content=False` because we want to make<br/>           `preload_content=False` the default behaviour someday soon without<br/>           breaking backwards compatibility.<br/>    <br/>        :param method:<br/>            HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>        :param body:<br/>            Data to send in the request body (useful for creating<br/>            POST requests, see HTTPConnectionPool.post_url for<br/>            more convenience).<br/>    <br/>        :param headers:<br/>            Dictionary of custom headers to send, such as User-Agent,<br/>            If-None-Match, etc. If None, pool headers are used. If provided,<br/>            these headers completely replace any pool-specific headers.<br/>    <br/>        :param retries:<br/>            Configure the number of retries to allow before raising a<br/>            :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>            Pass ``None`` to retry until you receive a response. Pass a<br/>            :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>            over different types of retries.<br/>            Pass an integer number to retry connection errors that many times,<br/>            but no other types of errors. Pass zero to never retry.<br/>    <br/>            If ``False``, then retries are disabled and any exception is raised<br/>            immediately. Also, instead of raising a MaxRetryError on redirects,<br/>            the redirect response will be returned.<br/>    <br/>        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>        :param redirect:<br/>            If True, automatically handle redirects (status codes 301, 302,<br/>            303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>            will disable redirect, too.<br/>    <br/>        :param assert_same_host:<br/>            If ``True``, will make sure that the host of the pool requests is<br/>            consistent else will raise HostChangedError. When False, you can<br/>            use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>        :param timeout:<br/>            If specified, overrides the default timeout for this one<br/>            request. It may be a float (in seconds) or an instance of<br/>            :class:`urllib3.util.Timeout`.<br/>    <br/>        :param pool_timeout:<br/>            If set and the pool is set to block=True, then this method will<br/>            block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>            connection is available within the time period.<br/>    <br/>        :param release_conn:<br/>            If False, then the urlopen call will not release the connection<br/>            back into the pool once a response is received (but will release if<br/>            you read the entire contents of the response such as when<br/>            `preload_content=True`). This is useful if you&#x27;re not preloading<br/>            the response&#x27;s content immediately. You will need to call<br/>            ``r.release_conn()`` on the response ``r`` to return the connection<br/>            back into the pool. If None, it takes the value of<br/>            ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>        :param chunked:<br/>            If True, urllib3 will send the body using chunked transfer<br/>            encoding. Otherwise, urllib3 will send the body using the standard<br/>            content-length form. Defaults to False.<br/>    <br/>        :param int body_pos:<br/>            Position to seek to in file-like body in the event of a retry or<br/>            redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>            auto-populate the value when needed.<br/>    <br/>        :param \\**response_kw:<br/>            Additional parameters are passed to<br/>            :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>        &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/lib/python3.7/site-packages/urllib3/connectionpool.py:641: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;<br/>url = &#x27;/super_table/search_by_name/?name=%E7%81%AD%E9%9C%B8&amp;md5_sign=327fbe6a4c7a11276180db4f75f1f8ed%7C1558167163&#x27;<br/>response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f7a956e8cc0&gt;<br/>_stacktrace = &lt;traceback object at 0x7f7a95527448&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>        :param response: A response object, or None, if the server did not<br/>            return a response.<br/>        :type response: :class:`~urllib3.response.HTTPResponse`<br/>        :param Exception error: An error encountered during the request, or<br/>            None if the response was received successfully.<br/>    <br/>        :return: A new ``Retry`` object.<br/>        &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/search_by_name/?name=%E7%81%AD%E9%9C%B8&amp;md5_sign=327fbe6a4c7a11276180db4f75f1f8ed%7C1558167163 (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/urllib3/util/retry.py:399: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;test_main.TestApi object at 0x7f7a9575e710&gt;, num = 4.0<br/>api_name = &#x27;查询人物信息&#x27;, description = &#x27;查询成功&#x27;<br/>api_host = &#x27;http://127.0.0.1:8000/\n&#x27;<br/>request_url = &#x27;super_table/search_by_name/&#x27;, request_method = &#x27;GET&#x27;<br/>request_data = &#x27;{&quot;name&quot;: &quot;灭霸&quot;}&#x27;, encryption_method = &#x27;MD5&#x27;<br/>check_point = &#x27;200:success&#x27;, active = &#x27;yes&#x27;<br/><br/>    @pytest.mark.parametrize(&#x27;num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active&#x27;, excel)<br/>    # 测试用例<br/>    def test_api(self, num, api_name, description, api_host, request_url, request_method, request_data, encryption_method, check_point, active):<br/>        # 拼接出完整请求地址<br/>        url = api_host.replace(&#x27;\n&#x27;, &#x27;&#x27;).replace(&#x27;\r&#x27;, &#x27;&#x27;) + request_url<br/>        # 以防万一，如果用例未激活则跳过<br/>        if active == &quot;no&quot;:<br/>            pytest.skip(&quot;active为no，跳过该测试用例&quot;)<br/>        elif active == &quot;yes&quot;:<br/>            # 处理GET请求<br/>            if  request_method == &quot;GET&quot;:<br/>                # 如果请求需要MD5签名<br/>                if encryption_method == &#x27;MD5&#x27;:<br/>                    data = json.loads(request_data)<br/>                    sign = encryption.MD5_sign()<br/>                    data.update(md5_sign=sign)<br/>                    session = requests.Session()<br/>                    # 禁止代理服务<br/>                    session.trust_env = False<br/>&gt;                   r = session.get(url, params=data)<br/><br/>test_main.py:35: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:546: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:533: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/lib/python3.7/site-packages/requests/sessions.py:646: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f7a955e8898&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f7a956e8e48&gt;<br/>verify = True, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>        :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>        :param stream: (optional) Whether to stream the request content.<br/>        :param timeout: (optional) How long to wait for the server to send<br/>            data before giving up, as a float, or a :ref:`(connect timeout,<br/>            read timeout) &lt;timeouts&gt;` tuple.<br/>        :type timeout: float or tuple or urllib3 Timeout object<br/>        :param verify: (optional) Either a boolean, in which case it controls whether<br/>            we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>            must be a path to a CA bundle to use<br/>        :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>        :param proxies: (optional) The proxies dictionary to apply to the request.<br/>        :rtype: requests.Response<br/>        &quot;&quot;&quot;<br/>    <br/>        try:<br/>            conn = self.get_connection(request.url, proxies)<br/>        except LocationValueError as e:<br/>            raise InvalidURL(e, request=request)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7, use buffering of HTTP responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 3.3+<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;127.0.0.1&#x27;, port=8000): Max retries exceeded with url: /super_table/search_by_name/?name=%E7%81%AD%E9%9C%B8&amp;md5_sign=327fbe6a4c7a11276180db4f75f1f8ed%7C1558167163 (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f7a956ff240&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br/><br/>/usr/lib/python3.7/site-packages/requests/adapters.py:516: ConnectionError<br/></div></td></tr></tbody></table></body></html>